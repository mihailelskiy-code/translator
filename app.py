import asyncio
import logging
import re
import tempfile
from pathlib import Path
from typing import Tuple
import os

from aiogram import Bot, Dispatcher, F
from aiogram.filters import CommandStart
from aiogram.types import FSInputFile, Message
from deep_translator import GoogleTranslator
from gtts import gTTS
from pydub import AudioSegment
import speech_recognition as sr

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Ð¢Ð¾ÐºÐµÐ½ Ð±ÐµÑ€Ñ‘Ð¼ Ð¸Ð· Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ BOT_TOKEN
BOT_TOKEN = os.getenv("BOT_TOKEN")
if not BOT_TOKEN:
    raise RuntimeError("BOT_TOKEN environment variable is not set")

translator_ru_to_de = GoogleTranslator(source="ru", target="de")
translator_de_to_ru = GoogleTranslator(source="de", target="ru")
recognizer = sr.Recognizer()


def detect_language(text: str) -> str:
    """ÐžÑ‡ÐµÐ½ÑŒ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹ Ð´ÐµÑ‚ÐµÐºÑ‚Ð¾Ñ€ ÑÐ·Ñ‹ÐºÐ°: ÐµÑÑ‚ÑŒ ÐºÐ¸Ñ€Ð¸Ð»Ð»Ð¸Ñ†Ð° â†’ ru, Ð¸Ð½Ð°Ñ‡Ðµ â†’ de."""
    return "ru" if re.search(r"[\u0400-\u04FF]", text) else "de"


def translate(text: str) -> Tuple[str, str]:
    """ÐŸÐµÑ€ÐµÐ²Ð¾Ð´ RU â‡„ DE. Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ (Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´, Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ_ÑÑ‚Ñ€Ð¾ÐºÐ¾Ð¹)."""
    source_lang = detect_language(text)
    translator = translator_ru_to_de if source_lang == "ru" else translator_de_to_ru
    translated = translator.translate(text)
    direction = "ðŸ‡·ðŸ‡ºâ†’ðŸ‡©ðŸ‡ª" if source_lang == "ru" else "ðŸ‡©ðŸ‡ªâ†’ðŸ‡·ðŸ‡º"
    return translated, direction


def synthesize_speech(text: str, lang: str) -> Path:
    """TTS Ñ‡ÐµÑ€ÐµÐ· gTTS â†’ mp3 â†’ ogg/opus Ð´Ð»Ñ voice-ÐºÑ€ÑƒÐ¶ÐºÐ°."""
    mp3_file = Path(tempfile.mkstemp(suffix=".mp3")[1])
    ogg_file = Path(tempfile.mkstemp(suffix=".ogg")[1])

    gTTS(text=text, lang=lang).save(str(mp3_file))

    audio = AudioSegment.from_mp3(mp3_file)
    audio = audio.set_frame_rate(48000).set_channels(1)
    audio.export(ogg_file, format="ogg", codec="libopus")

    mp3_file.unlink(missing_ok=True)
    return ogg_file


def convert_voice_to_wav(source_path: Path) -> Path:
    """Ð¢ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼-voice (ogg/opus) â†’ WAV Ð´Ð»Ñ SpeechRecognition."""
    wav_path = Path(tempfile.mkstemp(suffix=".wav")[1])
    audio = AudioSegment.from_file(source_path)
    audio = audio.set_frame_rate(16000).set_channels(1)
    audio.export(wav_path, format="wav")
    return wav_path


def recognize_speech(audio_path: Path) -> str:
    """ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ñ‚ÑŒ ÑÐ½Ð°Ñ‡Ð°Ð»Ð° RU, Ð¿Ð¾Ñ‚Ð¾Ð¼ DE."""
    with sr.AudioFile(str(audio_path)) as source:
        audio = recognizer.record(source)
    for language_code in ("ru-RU", "de-DE"):
        try:
            return recognizer.recognize_google(audio, language=language_code)
        except sr.UnknownValueError:
            continue
    raise sr.UnknownValueError("Speech could not be recognized in supported languages")


async def handle_start(message: Message) -> None:
    help_text = (
        "ðŸ‘‹ Ð¯ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ñ‡Ð¸Ðº Ð¼ÐµÐ¶Ð´Ñƒ Ñ€ÑƒÑÑÐºÐ¸Ð¼ Ð¸ Ð½ÐµÐ¼ÐµÑ†ÐºÐ¸Ð¼.\n\n"
        "â€¢ ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ Ð¸Ð»Ð¸ Ð½ÐµÐ¼ÐµÑ†ÐºÐ¾Ð¼ â€” Ð¿ÐµÑ€ÐµÐ²ÐµÐ´Ñƒ Ð½Ð° Ð¿Ñ€Ð¾Ñ‚Ð¸Ð²Ð¾Ð¿Ð¾Ð»Ð¾Ð¶Ð½Ñ‹Ð¹ ÑÐ·Ñ‹Ðº.\n"
        "â€¢ ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒ voice â€” Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°ÑŽ, Ð¿ÐµÑ€ÐµÐ²ÐµÐ´Ñƒ Ð¸ Ð¿Ñ€Ð¸ÑˆÐ»ÑŽ Ð¾Ð·Ð²ÑƒÑ‡ÐºÑƒ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ð° ÐºÑ€ÑƒÐ¶ÐºÐ¾Ð¼.\n"
        "Ð Ð°Ð±Ð¾Ñ‚Ð°ÑŽ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð² Ñ€ÐµÐ¶Ð¸Ð¼Ðµ ðŸ‡·ðŸ‡ºâ‡„ðŸ‡©ðŸ‡ª."
    )
    await message.answer(help_text)


async def handle_text(message: Message) -> None:
    text = (message.text or "").strip()
    if not text:
        return

    translated, direction = translate(text)
    await message.answer(f"{direction}\n{translated}")

    target_lang = "de" if direction == "ðŸ‡·ðŸ‡ºâ†’ðŸ‡©ðŸ‡ª" else "ru"
    voice_path = synthesize_speech(translated, target_lang)
    try:
        await message.answer_voice(voice=FSInputFile(voice_path))
    finally:
        voice_path.unlink(missing_ok=True)


async def handle_voice(message: Message) -> None:
    note = await message.answer("ðŸŽ§ ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµâ€¦")

    ogg_file = Path(tempfile.mkstemp(suffix=".ogg")[1])
    wav_file: Path | None = None
    voice_path: Path | None = None

    try:
        await message.voice.download(destination=ogg_file)

        wav_file = convert_voice_to_wav(ogg_file)

        recognized_text = recognize_speech(wav_file)
        await note.edit_text(f"ðŸ—£ Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð¾: {recognized_text}")

        translated, direction = translate(recognized_text)
        await message.answer(f"{direction}\n{translated}")

        target_lang = "de" if direction == "ðŸ‡·ðŸ‡ºâ†’ðŸ‡©ðŸ‡ª" else "ru"
        voice_path = synthesize_speech(translated, target_lang)
        await message.answer_voice(voice=FSInputFile(voice_path))

    except sr.UnknownValueError:
        await note.edit_text("ðŸ˜” ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ñ‚ÑŒ Ñ€ÐµÑ‡ÑŒ. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ ÐµÑ‰Ñ‘ Ñ€Ð°Ð·.")
    except Exception:
        logger.exception("Error while handling voice message")
        await note.edit_text("âš ï¸ ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ.")
    finally:
        ogg_file.unlink(missing_ok=True)
        if wav_file:
            wav_file.unlink(missing_ok=True)
        if voice_path:
            voice_path.unlink(missing_ok=True)


def register_handlers(dp: Dispatcher) -> None:
    dp.message.register(handle_start, CommandStart())
    dp.message.register(handle_voice, F.voice)
    dp.message.register(handle_text, F.text)


async def main() -> None:
    bot = Bot(BOT_TOKEN)
    dp = Dispatcher()
    register_handlers(dp)
    print("âœ… Ð‘Ð¾Ñ‚ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½")
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())
